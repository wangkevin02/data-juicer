# global parameters
project_name: 'pretrain_text_dedup_cn_科技_科学研究01'
# 旧的需要保留的放在前面，新的数据代去重的路径(dir or file)放在第二个位置
dataset_path: ['/apdcephfs_cq8/share_2906397/users/wangkuang/pretrain_text_data/knowledge_intensive/baidu-wiki-500w/processed_merge.jsonl', '/apdcephfs_cq8/share_2906397/users/wangkuang/pretrain_text_data/knowledge_intensive/baike_900w/processed_test_bench.jsonl']  # path to your dataset directory or file
suffixes: ['jsonl']
ds_cache_dir: "./ds_cache_dir"
temp_dir: "./ds_temp_dir"
text_keys: 'raw_content'   
# 新去重后剩余的数据放置的位置
export_path: './outputs/demo-dedup-ray-bts/processed.jsonl'

np: 256
open_tracer: false
open_monitor: false
use_cache: false
executor_type: 'ray'  # 将执行器类型设置为 "ray"
ray_address: 'auto'  # 设置为自动 Ray 地址

# process schedule
process:
    - ray_bts_minhash_deduplicator: # 9873214
        tokenization: space
        window_size: 6  # small window size for short texts
        lowercase: true
        ignore_pattern: '\p{P}'
        num_blocks: 6
        hamming_distance: 4  # larger hamming distance threshold for short texts
    - general_field_filter:
        filter_condition: "tag > 0"